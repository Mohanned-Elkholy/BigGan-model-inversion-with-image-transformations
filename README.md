# BigGan-model-inversion-with-image-transformations
Model inversion has been one of the hot topics recently in deep learning. This the torch implementation of (https://arxiv.org/abs/1907.07171) .The idea behind model inversion is to find the closest image generated by a one of the state of the art generators to a given image. In most of the cases, the BigGan generator (https://arxiv.org/abs/1809.11096) is used for this problem.

---

# Advanced data augmentation using transformations in the latent space
It has been known that applying certain image transformations (like sliding left or right, center crop,..etc) are usually discrete and the image as a whole lacks continuity in some filters (like zero-padding). Applying this transformations in the latent space, however, is different because generative models are trained to produce realistic images. Thus, more ralistic image augmentation will happen in the latent space. In this repo, multiple transformations (sliding left, right, upwards, downwards and zooming) are done to a given image in the latent space of the BigGan generator. This data augmentation technique can be crucial in improving the accuracy of image classifiers. 

#add GIF here

---

# Prerequisites
1- python3 

2- CPU or NVIDIA GPU + CUDA CuDNN (GPU is recommended for faster inversion)


# Install dependencies
In this repo, a pretrained biggan in a specified library
```python
pip install torch torchvision matplotlib lpips numpy nltk cv2 pytorch-pretrained-biggan
```

# Training
#provide image to work on
```python
python train.py --image_path '/image.rgb' --loss ['l1','lpips_alexnet'] --transforms ['zoom','slide_left','slide_right','slide_upward','slide_downward'] --num_epochs 2000 --num_samples 6 --learning_rate 0.007 
```

# How does the optimization work
In the very beginning, a random input is chosen. Later the model is frozen and multiple backward propagations happen. The loss function in the back propagation tries to make the produced image and the target image as clos as possible. Since the model is frozen, the gradient updates only changes the latent input until the produced image matches a close representation in the latent space to the target image. 

# Truncation trick
Truncation trick is first introduced in the BigGan paper (https://arxiv.org/abs/1809.11096). Since the random input is chosen from a normal distribution, most of the training happens for random input values that range from (-1 to 1). In the inversion task, the latent input is truncated after each gradient update: (values that are less than -1 or more than 1 are set to a random value). This ensures the realisticity of the image as well as help avoid local minima in the generator manifold.
